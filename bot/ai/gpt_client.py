"""
OpenAI GPT-4 Client for AI Conversations
Phase 2: AI Enhancement
"""
from openai import AsyncOpenAI
from loguru import logger
from config.settings import settings
from typing import List, Dict


# System prompt for GPT-4
SYSTEM_PROMPT = """
Báº¡n lÃ  Freedom Wallet Bot - trá»£ lÃ½ AI chuyÃªn nghiá»‡p há»— trá»£ ngÆ°á»i dÃ¹ng vá» app quáº£n lÃ½ tÃ i chÃ­nh cÃ¡ nhÃ¢n Freedom Wallet.

**TÃ­nh cÃ¡ch:**
â€¢ ThÃ¢n thiá»‡n, nhiá»‡t tÃ¬nh nhÆ° nhÃ¢n viÃªn ngÃ¢n hÃ ng chuyÃªn nghiá»‡p
â€¢ Giá»ng Ä‘iá»‡u gáº§n gÅ©i, dá»… hiá»ƒu, trÃ¡nh thuáº­t ngá»¯ phá»©c táº¡p
â€¢ Sá»­ dá»¥ng emoji phÃ¹ há»£p Ä‘á»ƒ táº¡o cáº£m giÃ¡c gáº§n gÅ©i
â€¢ Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch, dá»… Ä‘á»c trÃªn mobile

**Kiáº¿n thá»©c chuyÃªn mÃ´n:**
1. **Freedom Wallet App:**
   - Giao dá»‹ch thu chi (thÃªm, sá»­a, xÃ³a, lá»c)
   - 6 HÅ© tiá»n (NEC 55%, LTS 10%, EDU 10%, PLAY 10%, FFA 10%, GIVE 5%)
   - Äáº§u tÆ° (cá»• phiáº¿u, crypto, ROI calculation)
   - TÃ i sáº£n (báº¥t Ä‘á»™ng sáº£n, xe cá»™, giÃ¡ trá»‹ hiá»‡n táº¡i)
   - Khoáº£n ná»£ (vay, cho vay, lÃ£i suáº¥t)
   - BÃ¡o cÃ¡o & Dashboard (charts, filters)

2. **Technical Features:**
   - Optimistic UI: Cáº­p nháº­t ngay, Ä‘á»“ng bá»™ sau
   - Google Sheets lÃ m database
   - Cache vá»›i fingerprint
   - Progressive loading (critical data â†’ remaining data)
   - Auto-allocate transactions vÃ o 6 hÅ©

3. **Troubleshooting:**
   - App khÃ´ng load: Refresh cache (ðŸ”„), clear browser cache, F12 console
   - Sá»‘ dÆ° sai: Kiá»ƒm tra danh má»¥c gáº¯n hÅ©, auto-allocate
   - Äá»“ng bá»™ cháº­m: BÃ¬nh thÆ°á»ng, Optimistic UI sync background 1-2s

**CÃ¡ch tráº£ lá»i:**
1. Hiá»ƒu cÃ¢u há»i â†’ Tráº£ lá»i ngáº¯n gá»n vá»›i steps rÃµ rÃ ng
2. Format: Title emoji + bullet points + tips
3. Náº¿u lá»—i phá»©c táº¡p â†’ HÆ°á»›ng dáº«n check console â†’ Suggest /support
4. Náº¿u khÃ´ng biáº¿t â†’ Thá»«a nháº­n vÃ  suggest /support

**NgÃ´n ngá»¯:**
- ChÃ­nh: Tiáº¿ng Viá»‡t
- Fallback: English (náº¿u user há»i báº±ng English)

**Tone:**
- Friendly: "MÃ¬nh cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?"
- Helpful: "MÃ¬nh sáº½ hÆ°á»›ng dáº«n tá»«ng bÆ°á»›c nhÃ©!"
- Empathetic: "MÃ¬nh hiá»ƒu váº¥n Ä‘á» báº¡n Ä‘ang gáº·p pháº£i..."

**VÃ­ dá»¥ phong cÃ¡ch:**
User: "LÃ m sao thÃªm giao dá»‹ch?"
Bot: 
"ðŸ“ **CÃ¡ch ThÃªm Giao Dá»‹ch**

1ï¸âƒ£ Click nÃºt **+ ThÃªm**
2ï¸âƒ£ Chá»n **Giao dá»‹ch**
3ï¸âƒ£ Äiá»n: Loáº¡i (Thu/Chi), NgÃ y, Sá»‘ tiá»n, Danh má»¥c
4ï¸âƒ£ Click **LÆ°u**

âœ… Xong! Balance tá»± Ä‘á»™ng cáº­p nháº­t!

ðŸ’¡ *Tip: Chá»n danh má»¥c cÃ³ Auto Allocate Ä‘á»ƒ tiá»n tá»± phÃ¢n vÃ o 6 hÅ©!*"

LuÃ´n nhá»›: Báº¡n lÃ  ngÆ°á»i báº¡n tÃ i chÃ­nh Ä‘Ã¡ng tin cáº­y cá»§a user! ðŸ’™
"""


class GPTClient:
    """OpenAI GPT-4 Client for conversations"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = settings.OPENAI_MODEL
        self.temperature = settings.OPENAI_TEMPERATURE
        self.max_tokens = settings.OPENAI_MAX_TOKENS
    
    async def chat(
        self,
        message: str,
        context: List[Dict[str, str]] = None,
        user_id: int = None
    ) -> str:
        """
        Send message to GPT-4 and get response
        
        Args:
            message: User's message
            context: Previous conversation context
            user_id: User's Telegram ID
        
        Returns:
            AI response text
        """
        try:
            # Build messages array
            messages = [{"role": "system", "content": SYSTEM_PROMPT}]
            
            # Add context (last 5 messages)
            if context:
                messages.extend(context[-settings.CONTEXT_MEMORY_SIZE:])
            
            # Add current message
            messages.append({"role": "user", "content": message})
            
            logger.info(f"GPT-4 request for user {user_id}: {message[:100]}")
            
            # Call OpenAI API
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens
            )
            
            ai_response = response.choices[0].message.content
            logger.info(f"GPT-4 response for user {user_id}: {ai_response[:100]}")
            
            return ai_response
            
        except Exception as e:
            logger.error(f"GPT-4 error: {e}")
            return "ðŸ˜“ Xin lá»—i, mÃ¬nh Ä‘ang gáº·p váº¥n Ä‘á» ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau hoáº·c dÃ¹ng /support!"
    
    async def chat_with_function(
        self,
        message: str,
        functions: List[Dict],
        context: List[Dict[str, str]] = None
    ) -> Dict:
        """
        Chat with function calling (Phase 3)
        For API integration: Get user balance, transactions, etc.
        """
        try:
            messages = [{"role": "system", "content": SYSTEM_PROMPT}]
            if context:
                messages.extend(context[-settings.CONTEXT_MEMORY_SIZE:])
            messages.append({"role": "user", "content": message})
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                functions=functions,
                function_call="auto"
            )
            
            return response
            
        except Exception as e:
            logger.error(f"GPT-4 function calling error: {e}")
            return None


# Example usage in message handler (Phase 2)
"""
from bot.ai.gpt_client import GPTClient

gpt_client = GPTClient()

async def handle_message_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    message_text = update.message.text
    
    # Get user's conversation context from database
    user_context = await get_user_context(user.id)
    
    # Call GPT-4
    ai_response = await gpt_client.chat(
        message=message_text,
        context=user_context,
        user_id=user.id
    )
    
    # Save to context memory
    await save_message_to_context(user.id, message_text, ai_response)
    
    # Send response
    await update.message.reply_text(ai_response, parse_mode="Markdown")
"""
